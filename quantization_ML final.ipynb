{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data preprocessing\n",
    "df = pd.read_excel('questions.xlsx',header=None)\n",
    "\n",
    "questions = pd.DataFrame(columns=['Question', 'Colour', 'Concept', 'Discipline', 'Place'])\n",
    "scores = pd.DataFrame(columns=['Question', 'Colour', 'Concept', 'Discipline', 'Place'])\n",
    "\n",
    "preferences = pd.read_csv('perference_transformed.csv')\n",
    "user_preferences = preferences.iloc[20-1].to_dict()\n",
    "\n",
    "decision_datas = pd.read_csv('decision.csv',header=None)\n",
    "decision_data = decision_datas[decision_datas.iloc[:, 0] == 20]\n",
    "\n",
    "groups = {\n",
    "    'Colour': ['PURPLE', 'BLUE', 'GREEN', 'RED', 'ORANGE'],\n",
    "    'Concept': ['RISK', 'HOPE', 'SAFETY', 'VITALITY', 'POWER'],\n",
    "    'Discipline': ['LITERATURE', 'PHYSICS', 'MUSIC', 'HISTORY', 'GEOGRAPHY'],\n",
    "    'Place': ['SEA', 'DESERT', 'CITY', 'MOUNTAIN', 'VILLAGE']\n",
    "}\n",
    "\n",
    "value_to_group = {\n",
    "    value: group\n",
    "    for group, values in groups.items()\n",
    "    for value in values\n",
    "}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    question_num = row.iloc[0]\n",
    "    groups = re.findall(r'([A-Z]+) - (\\d+), ([A-Z]+) - (\\d+), ([A-Z]+) - (\\d+), ([A-Z]+) - (\\d+)', row.iloc[1])\n",
    "    if groups:\n",
    "        groups = groups[0]\n",
    "        question_row = {\n",
    "            'Question': question_num,\n",
    "            'Colour': groups[0],\n",
    "            'Concept': groups[2],\n",
    "            'Discipline': groups[4],\n",
    "            'Place': groups[6]\n",
    "        }\n",
    "        score_row = {\n",
    "            'Question': question_num,\n",
    "            'Colour': int(groups[1]),\n",
    "            'Concept': int(groups[3]),\n",
    "            'Discipline': int(groups[5]),\n",
    "            'Place': int(groups[7])\n",
    "        }\n",
    "        \n",
    "        questions = pd.concat([questions, pd.DataFrame([question_row])], ignore_index=True)\n",
    "        scores = pd.concat([scores, pd.DataFrame([score_row])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BehavioralModel:\n",
    "    # initialization\n",
    "    def __init__(self, questions, scores, decision_data, user_preferences,\n",
    "                 SC=0.5, G=0.5, adve=0.5, Sub=0.5,\n",
    "                 lr=0.1, eps_grad=1e-5, beta=0.9, verbose=False):\n",
    "\n",
    "        self.questions = questions.reset_index(drop=True)\n",
    "        self.scores = scores.reset_index(drop=True)\n",
    "        self.decision_data = decision_data.reset_index(drop=True)\n",
    "\n",
    "        self.q_col = 1\n",
    "        self.chosen_word_col = 2\n",
    "\n",
    "        self.groups = {\n",
    "            'Colour': ['PURPLE', 'BLUE', 'GREEN', 'RED', 'ORANGE'],\n",
    "            'Concept': ['RISK', 'HOPE', 'SAFETY', 'VITALITY', 'POWER'],\n",
    "            'Discipline': ['LITERATURE', 'PHYSICS', 'MUSIC', 'HISTORY', 'GEOGRAPHY'],\n",
    "            'Place': ['SEA', 'DESERT', 'CITY', 'MOUNTAIN', 'VILLAGE']\n",
    "        }\n",
    "\n",
    "        self.user_preferences = dict(user_preferences)\n",
    "        self.value_to_group = {v: k for k, vals in self.groups.items() for v in vals}\n",
    "\n",
    "        self.group_preferences = {\n",
    "            grp: np.mean([self.user_preferences.get(w, 2.5) for w in words])\n",
    "            for grp, words in self.groups.items()\n",
    "        }\n",
    "\n",
    "        # learnable parameters\n",
    "        self.SC = float(SC)\n",
    "        self.G = float(G)\n",
    "        self.adve = float(adve)\n",
    "        self.Sub = float(Sub)\n",
    "        self.lr = float(lr)\n",
    "        self.eps_grad = float(eps_grad)\n",
    "        self.beta = float(beta)\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # momentum\n",
    "        self.v_SC = 0.0\n",
    "        self.v_G = 0.0\n",
    "        self.v_adve = 0.0\n",
    "        self.v_Sub = 0.0\n",
    "\n",
    "        # memory: key = word, vals = list of past scores\n",
    "        self.memory = {w: [] for w in self.value_to_group}\n",
    "        self.group_memory = {grp: [] for grp in self.groups}\n",
    "\n",
    "\n",
    "    # memory update\n",
    "    def _add_memory_record(self, qnum):\n",
    "        idx = self.questions.index[self.questions[\"Question\"].astype(int) == int(qnum)][0]\n",
    "        word_map = {\n",
    "            'Colour': self.questions.loc[idx, 'Colour'],\n",
    "            'Concept': self.questions.loc[idx, 'Concept'],\n",
    "            'Discipline': self.questions.loc[idx, 'Discipline'],\n",
    "            'Place': self.questions.loc[idx, 'Place']\n",
    "        }\n",
    "        score_map = {\n",
    "            'Colour': int(self.scores.loc[idx, 'Colour']),\n",
    "            'Concept': int(self.scores.loc[idx, 'Concept']),\n",
    "            'Discipline': int(self.scores.loc[idx, 'Discipline']),\n",
    "            'Place': int(self.scores.loc[idx, 'Place'])\n",
    "        }\n",
    "\n",
    "        for grp, w in word_map.items():\n",
    "            self.memory[w].append(score_map[grp])\n",
    "        for grp in score_map:\n",
    "            self.group_memory[grp].append(score_map[grp])\n",
    "\n",
    "    # Calculate the mean and standard deviation\n",
    "    def _compute_stats_for_item(self, word):\n",
    "        vals = self.memory[word]\n",
    "        if not vals:\n",
    "            return 0, 0\n",
    "        arr = np.array(vals, float)\n",
    "        return float(arr.mean()), float(arr.std())\n",
    "\n",
    "    def _compute_group_stats(self, group):\n",
    "        vals = []\n",
    "        for w in self.groups[group]:\n",
    "            vals.extend(self.memory[w])\n",
    "        if not vals:\n",
    "            return 0, 0\n",
    "        arr = np.array(vals, float)\n",
    "        return float(arr.mean()), float(arr.std())\n",
    "\n",
    "    # SC score (The average of the first two scores) \n",
    "    # (After testing, the effect of retaining twice was the best)\n",
    "    def _SC_score(self, history_values):\n",
    "        if len(history_values) == 0:\n",
    "            return 2.5\n",
    "        else:\n",
    "            return float(history_values[-1])\n",
    "\n",
    "    # signal (Various parameters and variables are weighted to obtain)\n",
    "    def _compute_option_signal(self, word, group):\n",
    "        pref_word = float(self.user_preferences.get(word, 2.5))\n",
    "        pref_group = float(self.group_preferences.get(group, 2.5))\n",
    "        pref_final = self.G * pref_group + (1 - self.G) * pref_word\n",
    "\n",
    "        w_mean, w_std = self._compute_stats_for_item(word)\n",
    "        g_mean, g_std = self._compute_group_stats(group)\n",
    "\n",
    "        mean_final = self.G * g_mean + (1 - self.G) * w_mean\n",
    "        std_final = self.G * g_std + (1 - self.G) * w_std\n",
    "        meanstd = (mean_final + (2 * self.adve - 1) * std_final)\n",
    "\n",
    "        w_sc = self._SC_score(self.memory[word])\n",
    "        g_sc = self._SC_score(self.group_memory[group])\n",
    "        SC_final = self.G * g_sc + (1 - self.G) * w_sc\n",
    "\n",
    "        return self.Sub * pref_final + (1 - self.Sub) * (self.SC * SC_final + (1 - self.SC) * meanstd)\n",
    "\n",
    "    # choice probabilities (Widen the gap)\n",
    "    def _compute_choice_probabilities(self, qnum):\n",
    "        idx = self.questions.index[self.questions[\"Question\"].astype(int) == int(qnum)][0]\n",
    "        opts = {\n",
    "            'Colour': self.questions.loc[idx, 'Colour'],\n",
    "            'Concept': self.questions.loc[idx, 'Concept'],\n",
    "            'Discipline': self.questions.loc[idx, 'Discipline'],\n",
    "            'Place': self.questions.loc[idx, 'Place']\n",
    "        }\n",
    "        signals = []\n",
    "        keys = []\n",
    "        for grp, w in opts.items():\n",
    "            keys.append((grp, w))\n",
    "            signals.append(self._compute_option_signal(w, grp))\n",
    "        arr = np.array(signals)\n",
    "        exps = np.exp(arr - arr.max())\n",
    "        probs = exps / exps.sum() * 100\n",
    "        return {k: p for k, p in zip(keys, probs)}\n",
    "\n",
    "    # preference update (Loss aversion and satisfaction)\n",
    "    def _update_preferences_after_reveal(self, qnum, selected_word):\n",
    "        idx = self.questions.index[self.questions[\"Question\"].astype(int) == int(qnum)][0]\n",
    "        scores = {\n",
    "            'Colour': int(self.scores.loc[idx, 'Colour']),\n",
    "            'Concept': int(self.scores.loc[idx, 'Concept']),\n",
    "            'Discipline': int(self.scores.loc[idx, 'Discipline']),\n",
    "            'Place': int(self.scores.loc[idx, 'Place'])\n",
    "        }\n",
    "        words = {\n",
    "            'Colour': self.questions.loc[idx, 'Colour'],\n",
    "            'Concept': self.questions.loc[idx, 'Concept'],\n",
    "            'Discipline': self.questions.loc[idx, 'Discipline'],\n",
    "            'Place': self.questions.loc[idx, 'Place']\n",
    "        }\n",
    "\n",
    "        for grp, w in words.items():\n",
    "            if w == selected_word:\n",
    "                delta = self.lr * np.abs(3 - scores[grp])\n",
    "                if scores[grp] >= 3:\n",
    "                    self.user_preferences[w] += delta\n",
    "                else:\n",
    "                    self.user_preferences[w] -= delta\n",
    "            else:\n",
    "                self.user_preferences[w] -= self.lr\n",
    "\n",
    "        for grp, w in words.items():\n",
    "            gscore = scores[grp]\n",
    "            delta = self.lr * self.Sub * 2\n",
    "            gp = self.group_preferences.get(grp, 2.5)\n",
    "            if grp == self.value_to_group[selected_word]:\n",
    "                gp = gp + delta if gscore >= 3 else gp - delta\n",
    "            else:\n",
    "                gp = gp - 0.25 * delta\n",
    "            self.group_preferences[grp] = gp\n",
    "\n",
    "    # training\n",
    "    def train(self, init_qs=None, train_qs=None, max_epochs=1, convergence_tol=1e-6):\n",
    "\n",
    "        if init_qs is None:\n",
    "            init_qs = list(self.questions[\"Question\"].iloc[:5].astype(int))\n",
    "        if train_qs is None:\n",
    "            train_qs = list(self.questions[\"Question\"].iloc[5:].astype(int))\n",
    "\n",
    "        self.memory = {w: [] for w in self.value_to_group}\n",
    "\n",
    "        for q in init_qs:\n",
    "            self._add_memory_record(q)\n",
    "            actual = self.decision_data[self.decision_data.iloc[:, self.q_col].astype(int) == q]\n",
    "            if len(actual):\n",
    "                selected_word = actual.iloc[0, self.chosen_word_col]\n",
    "                self._update_preferences_after_reveal(q, selected_word)\n",
    "\n",
    "        results = []\n",
    "        prev_loss = None\n",
    "\n",
    "        for ep in range(max_epochs):\n",
    "            total_loss = 0\n",
    "\n",
    "            for q in train_qs:\n",
    "                probs = self._compute_choice_probabilities(q)\n",
    "                pred_key, pred_prob = max(probs.items(), key=lambda x: x[1])\n",
    "                _, pred_word = pred_key\n",
    "                pred_prob /= 100\n",
    "\n",
    "                actual = self.decision_data[self.decision_data.iloc[:, self.q_col].astype(int) == q]\n",
    "                if not len(actual):\n",
    "                    self._add_memory_record(q)\n",
    "                    continue\n",
    "                actual_word = actual.iloc[0, self.chosen_word_col]\n",
    "\n",
    "                actual_prob = None\n",
    "                for (g, w), p in probs.items():\n",
    "                    if w == actual_word:\n",
    "                        actual_prob = p / 100\n",
    "                        break\n",
    "                if actual_prob is None:\n",
    "                    self._add_memory_record(q)\n",
    "                    continue\n",
    "\n",
    "                loss = 1 - actual_prob\n",
    "                total_loss += loss\n",
    "\n",
    "                results.append({\n",
    "                    \"Question\": q,\n",
    "                    \"PredWord\": pred_word,\n",
    "                    \"ActualWord\": actual_word,\n",
    "                    \"PredProb\": pred_prob * 100,\n",
    "                    \"ActualProb\": actual_prob * 100,\n",
    "                    \"Loss\": loss\n",
    "                })\n",
    "\n",
    "                results[-1][\"SC_val\"] = self.SC\n",
    "                results[-1][\"G_val\"] = self.G\n",
    "                results[-1][\"adve_val\"] = self.adve\n",
    "                results[-1][\"Sub_val\"] = self.Sub\n",
    "\n",
    "\n",
    "                # gradient\n",
    "                if pred_word != actual_word:\n",
    "                    base = np.array([self.SC, self.G, self.adve, self.Sub])\n",
    "                    grads = np.zeros_like(base)\n",
    "\n",
    "                    for i in range(len(base)):\n",
    "                        new = base.copy()\n",
    "                        new[i] += self.eps_grad\n",
    "                        temp = copy.deepcopy(self)\n",
    "                        temp.SC, temp.G, temp.adve, temp.Sub = new\n",
    "\n",
    "                        pert_probs = temp._compute_choice_probabilities(q)\n",
    "                        pert_actual = None\n",
    "                        for (g, w), p in pert_probs.items():\n",
    "                            if w == actual_word:\n",
    "                                pert_actual = p / 100\n",
    "                                break\n",
    "                        pert_loss = 1 - (pert_actual if pert_actual is not None else actual_prob)\n",
    "                        grads[i] = (pert_loss - loss) / self.eps_grad\n",
    "\n",
    "                    self.v_SC = self.beta * self.v_SC + self.lr * grads[0]\n",
    "                    self.v_G = self.beta * self.v_G + self.lr * grads[1]\n",
    "                    self.v_adve = self.beta * self.v_adve + self.lr * grads[2]\n",
    "                    self.v_Sub = self.beta * self.v_Sub + self.lr * grads[3]\n",
    "\n",
    "                    self.SC -= self.v_SC\n",
    "                    self.G -= self.v_G\n",
    "                    self.adve -= self.v_adve\n",
    "                    self.Sub -= self.v_Sub\n",
    "\n",
    "                    self.SC = np.clip(self.SC, 0, 1)\n",
    "                    self.G = np.clip(self.G, 0, 1)\n",
    "                    self.adve = np.clip(self.adve, 0, 1)\n",
    "                    self.Sub = np.clip(self.Sub, 0, 1)\n",
    "\n",
    "                self._update_preferences_after_reveal(q, actual_word)\n",
    "                self._add_memory_record(q)\n",
    "\n",
    "            avg_loss = total_loss / max(1, len(results))\n",
    "            if self.verbose:\n",
    "                print(f\"Epoch {ep+1} loss={avg_loss:.6f}  SC={self.SC:.3f} G={self.G:.3f} adve={self.adve:.3f} Sub={self.Sub:.3f}\")\n",
    "\n",
    "            if prev_loss is not None and abs(prev_loss - avg_loss) < convergence_tol:\n",
    "                break\n",
    "            prev_loss = avg_loss\n",
    "\n",
    "        return {\n",
    "            \"SC\": self.SC,\n",
    "            \"G\": self.G,\n",
    "            \"adve\": self.adve,\n",
    "            \"Sub\": self.Sub,\n",
    "            \"FinalPreferences\": self.user_preferences,\n",
    "            \"FinalGroupPrefer\": self.group_preferences\n",
    "        }, pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ce732",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "preferences = pd.read_csv('perference_transformed.csv')\n",
    "user_preferences = preferences.iloc[n-1].to_dict()\n",
    "\n",
    "decision_datas = pd.read_csv('decision.csv',header=None)\n",
    "decision_data = decision_datas[decision_datas.iloc[:, 0] == n]\n",
    "\n",
    "model = BehavioralModel(questions, scores, decision_data, user_preferences,\n",
    "                        lr=0.6, verbose=True)\n",
    "\n",
    "final_params, results_df = model.train(max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# The search range of the learning rate\n",
    "lr_grid = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09,\n",
    "           0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, \n",
    "           1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "results = []\n",
    "\n",
    "for n in range(1, 54):\n",
    "    # Read user preference data\n",
    "    preferences = pd.read_csv('perference_transformed.csv')\n",
    "    user_preferences = preferences.iloc[n-1].to_dict()\n",
    "    \n",
    "    # Read decision-making data\n",
    "    decision_datas = pd.read_csv('decision.csv', header=None)\n",
    "    decision_data = decision_datas[decision_datas.iloc[:, 0] == n]\n",
    "    \n",
    "    # Grid search for optimal parameters\n",
    "    best_accuracy = -1  # Initialize\n",
    "    best_params_list = []  # Save all the optimal parameter combinations\n",
    "    \n",
    "    for lr in lr_grid:\n",
    "        model = BehavioralModel(\n",
    "            questions, scores, decision_data, user_preferences,\n",
    "            lr=lr, verbose=False\n",
    "        )\n",
    "        \n",
    "        final_params, results_df = model.train(max_epochs=1)\n",
    "        \n",
    "        # Calculate the accuracy rate of the last 35 questions\n",
    "        subset = results_df.tail(35)\n",
    "        correct_count = (subset['PredWord'] == subset['ActualWord']).sum()\n",
    "        accuracy = correct_count / len(subset)\n",
    "        \n",
    "        # Extract the parameters and retain three decimal places\n",
    "        SC_rounded = round(float(final_params['SC']), 3)\n",
    "        g_rounded = round(float(final_params['G']), 3)\n",
    "        adve_rounded = round(float(final_params['adve']), 3)\n",
    "        sub_rounded = round(float(final_params['Sub']), 3)\n",
    "        \n",
    "        current_params = {\n",
    "            'lr': lr,\n",
    "            'SC': SC_rounded,\n",
    "            'G': g_rounded,\n",
    "            'adve': adve_rounded,\n",
    "            'Sub': sub_rounded,\n",
    "            'correct_count': int(correct_count),\n",
    "            'total_samples': len(subset)\n",
    "        }\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params_list = [current_params]  # Only retain the current best option\n",
    "        elif accuracy == best_accuracy:\n",
    "            best_params_list.append(current_params)  # With the same accuracy rate, add to the list\n",
    "    \n",
    "    # Generate a separate row for each optimal learning rate\n",
    "    for best_params in best_params_list:\n",
    "        results.append({\n",
    "            'n': n,\n",
    "            'accuracy': f\"{best_accuracy:.2%}\",\n",
    "            'lr': best_params['lr'],\n",
    "            'SC': best_params['SC'],\n",
    "            'G': best_params['G'],\n",
    "            'adve': best_params['adve'],\n",
    "            'Sub': best_params['Sub'],\n",
    "            'correct_count': best_params['correct_count'],\n",
    "            'total_samples': best_params['total_samples']\n",
    "        })\n",
    "\n",
    "# Save\n",
    "if results:\n",
    "    results_df_output = pd.DataFrame(results)\n",
    "    results_df_output = results_df_output.sort_values('n')\n",
    "    \n",
    "    column_order = ['n', 'accuracy', 'lr', 'SC', 'G', 'adve', 'Sub', 'correct_count', 'total_samples']\n",
    "    results_df_output = results_df_output[column_order]\n",
    "    \n",
    "    output_filename = 'lr_eps.csv'\n",
    "    results_df_output.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # Statistical Summary\n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    accuracy_values = [float(r['accuracy'].rstrip('%')) / 100 for r in results]\n",
    "    \n",
    "    print(f\"  Average best accuracy rate: {np.mean(accuracy_values):.2%}\")\n",
    "    print(f\"  Maximum accuracy rate: {np.max(accuracy_values):.2%}\")\n",
    "    print(f\"  Minimum accuracy rate: {np.min(accuracy_values):.2%}\")\n",
    "    print(f\"  Standard deviation: {np.std(accuracy_values):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_results = results_df_output.drop_duplicates('n', keep='first')\n",
    "accuracy_values = unique_results['accuracy'].apply(\n",
    "    lambda x: float(x.rstrip('%')) / 100\n",
    ").tolist()\n",
    "\n",
    "print(f\"Average best accuracy rate: {np.mean(accuracy_values):.2%}\")\n",
    "print(f\"Maximum accuracy rate: {np.max(accuracy_values):.2%}\")\n",
    "print(f\"Minimum accuracy rate: {np.min(accuracy_values):.2%}\")\n",
    "print(f\"Standard deviation: {np.std(accuracy_values):.2%}\")\n",
    "print(f\"Number of users: {len(accuracy_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda39fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "for i in range(1,36):\n",
    "    window = results_df.head(i)\n",
    "    correct = (window[\"PredWord\"] == window[\"ActualWord\"]).sum()\n",
    "    acc = correct / len(window)\n",
    "    acc_list.append(acc)\n",
    "\n",
    "results_df[\"Accuracy\"] = acc_list\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results_df[\"Question\"], results_df[\"Sub_val\"], label=\"Sub\")\n",
    "plt.plot(results_df[\"Question\"], results_df[\"SC_val\"], label=\"SC\")\n",
    "plt.plot(results_df[\"Question\"], results_df[\"G_val\"], label=\"G\")\n",
    "plt.plot(results_df[\"Question\"], results_df[\"adve_val\"], label=\"adve\")\n",
    "plt.plot(results_df[\"Question\"], results_df[\"Accuracy\"], label=\"Accuracy\", linewidth=2.3)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(26, 60)\n",
    "plt.xlabel(\"Question Number\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Parameter Trajectories and Accuracy (Questions 26-60)\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.35)\n",
    "plt.savefig(\"parameter_trajectories_and_accuracy_20.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021007d3-a876-4a5c-8ece-e17da2974347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file: 'strategy_scores.csv'\n",
      "Loaded file: 'decision.csv'\n",
      "\n",
      "==================================================\n",
      "Total Score Difference Comparison After GMM Clustering\n",
      "Clustering K=2, Statistical Test: Mann-Whitney U test\n",
      "==================================================\n",
      "Cluster 0 (N=40): Mean total score = 111.80, SD = 6.14\n",
      "Cluster 1 (N=13): Mean total score = 102.08, SD = 8.51\n",
      "--------------------------------------------------\n",
      "Statistic (Mann-Whitney U test Stat) = 448.0000\n",
      "p-value = 0.000105\n",
      "Difference direction: Cluster 0 > Cluster 1\n",
      "Statistical significance: *** (p < 0.001)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "STRATEGIES_ORDER = [\"Q-RL\", \"R-Item\", \"R-Cat\", \"LSC\", \"WSLS\", \"EV\", \"RA\", \"RS\", \"PD\"]\n",
    "CLUSTERING_K = 2\n",
    "\n",
    "def load_and_preprocess(filepath=\"strategy_scores.csv\", mock=False):\n",
    "    if not mock and os.path.exists(filepath):\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, index_col=\"participant_id\")\n",
    "            for col in df.columns:\n",
    "                if df[col].dtype == 'object':\n",
    "                    df[col] = df[col].astype(str).str.replace(\"%\", \"\", regex=False).astype(float) / 100.0\n",
    "                elif df[col].max() > 1.0:\n",
    "                    df[col] = df[col] / 100.0\n",
    "            print(f\"Loaded file: '{filepath}'\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file '{filepath}': {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Warning: File '{filepath}' not found or simulation enabled. Generating simulated strategy score data (N=50).\")\n",
    "        np.random.seed(42)\n",
    "        data = {}\n",
    "        for s in STRATEGIES_ORDER:\n",
    "            data[f\"{s}_all\"] = np.random.rand(50) * 0.5 + (0.5 * (s in [\"LSC\", \"WSLS\"]))\n",
    "        df = pd.DataFrame(data, index=[f\"P_{i}\" for i in range(50)])\n",
    "        return df\n",
    "\n",
    "def load_scores(filepath=\"decision.csv\", participant_ids=None, mock=False):\n",
    "    if not mock and os.path.exists(filepath):\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, header=None, names=['participant_id', 'trial', 'choice', 'score'])\n",
    "            print(f\"Loaded file: '{filepath}'\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file '{filepath}': {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Warning: File '{filepath}' not found or simulation enabled. Generating simulated decision score data (60 trials).\")\n",
    "        np.random.seed(42)\n",
    "        n_participants = len(participant_ids) if participant_ids is not None else 50\n",
    "        df_list = []\n",
    "        for i in range(n_participants):\n",
    "            pid = f\"P_{i}\"\n",
    "            scores = np.random.choice([0, 1], size=60, p=[0.3, 0.7])\n",
    "            df_part = pd.DataFrame({\n",
    "                'participant_id': pid,\n",
    "                'trial': range(1, 61),\n",
    "                'choice': np.random.randint(1, 5, 60),\n",
    "                'score': scores\n",
    "            })\n",
    "            df_list.append(df_part)\n",
    "        return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "def perform_gmm_clustering(df, k):\n",
    "    clustering_cols = [f\"{s}_all\" for s in STRATEGIES_ORDER]\n",
    "    X = df[clustering_cols]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    gmm = GaussianMixture(n_components=k, random_state=42, n_init=10)\n",
    "    cluster_labels = gmm.fit_predict(X_scaled)\n",
    "    return pd.Series(cluster_labels, index=df.index)\n",
    "\n",
    "def compare_cluster_total_scores(df_scores, cluster_labels):\n",
    "    df_scores['cluster_label'] = df_scores['participant_id'].map(cluster_labels)\n",
    "    participant_scores = df_scores.groupby('participant_id').agg({\n",
    "        'score': 'sum',\n",
    "        'cluster_label': 'first'\n",
    "    }).dropna().reset_index()\n",
    "\n",
    "    if participant_scores['cluster_label'].isnull().any():\n",
    "         print(\"Error: Participant ID mismatch between GMM clusters and decision score data. Skipping unmatched participants.\")\n",
    "\n",
    "    cluster_0_scores = participant_scores[participant_scores['cluster_label'] == 0]['score'].values\n",
    "    cluster_1_scores = participant_scores[participant_scores['cluster_label'] == 1]['score'].values\n",
    "\n",
    "    n0, n1 = len(cluster_0_scores), len(cluster_1_scores)\n",
    "    \n",
    "    if n0 < 3 or n1 < 3:\n",
    "        print(f\"Error: Cluster sample size too small (C0 N={n0}, C1 N={n1}). Statistical analysis aborted.\")\n",
    "        return\n",
    "\n",
    "    mean0, mean1 = np.mean(cluster_0_scores), np.mean(cluster_1_scores)\n",
    "    std0, std1 = np.std(cluster_0_scores, ddof=1), np.std(cluster_1_scores, ddof=1)\n",
    "\n",
    "    _, p_norm0 = stats.shapiro(cluster_0_scores)\n",
    "    _, p_norm1 = stats.shapiro(cluster_1_scores)\n",
    "    both_normal = (p_norm0 > 0.05) and (p_norm1 > 0.05)\n",
    "\n",
    "    if both_normal:\n",
    "        _, p_levene = stats.levene(cluster_0_scores, cluster_1_scores)\n",
    "        if p_levene > 0.05:\n",
    "            t_stat, p_value = stats.ttest_ind(cluster_0_scores, cluster_1_scores)\n",
    "            test_name = \"Independent samples t-test\"\n",
    "        else:\n",
    "            t_stat, p_value = stats.ttest_ind(cluster_0_scores, cluster_1_scores, equal_var=False)\n",
    "            test_name = \"Welch's t-test\"\n",
    "        statistic = t_stat\n",
    "    else:\n",
    "        u_stat, p_value = stats.mannwhitneyu(cluster_0_scores, cluster_1_scores, alternative='two-sided')\n",
    "        test_name = \"Mann-Whitney U test\"\n",
    "        statistic = u_stat\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Total Score Difference Comparison After GMM Clustering\")\n",
    "    print(f\"Clustering K={CLUSTERING_K}, Statistical Test: {test_name}\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Cluster 0 (N={n0}): Mean total score = {mean0:.2f}, SD = {std0:.2f}\")\n",
    "    print(f\"Cluster 1 (N={n1}): Mean total score = {mean1:.2f}, SD = {std1:.2f}\")\n",
    "\n",
    "    if mean0 > mean1:\n",
    "        direction = \"Cluster 0 > Cluster 1\"\n",
    "    elif mean0 < mean1:\n",
    "        direction = \"Cluster 0 < Cluster 1\"\n",
    "    else:\n",
    "        direction = \"No difference\"\n",
    "\n",
    "    if p_value < 0.001:\n",
    "        sig = \"*** (p < 0.001)\"\n",
    "    elif p_value < 0.01:\n",
    "        sig = \"** (p < 0.01)\"\n",
    "    elif p_value < 0.05:\n",
    "        sig = \"* (p < 0.05)\"\n",
    "    else:\n",
    "        sig = \"ns (not significant)\"\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Statistic ({test_name} Stat) = {statistic:.4f}\")\n",
    "    print(f\"p-value = {p_value:.6f}\")\n",
    "    print(f\"Difference direction: {direction}\")\n",
    "    print(f\"Statistical significance: {sig}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_strategy = load_and_preprocess(mock=False)\n",
    "    if df_strategy is None:\n",
    "        print(\"Note: Real strategy score file failed to load. Falling back to simulated data for demo.\")\n",
    "        df_strategy = load_and_preprocess(mock=True)\n",
    "\n",
    "    cluster_labels = perform_gmm_clustering(df_strategy, CLUSTERING_K)\n",
    "\n",
    "    df_scores = load_scores(participant_ids=df_strategy.index, mock=False)\n",
    "    \n",
    "    if df_scores is None:\n",
    "        print(\"Note: Real decision score file failed to load. Falling back to simulated data for demo.\")\n",
    "        df_scores = load_scores(participant_ids=df_strategy.index, mock=True)\n",
    "\n",
    "    compare_cluster_total_scores(df_scores, cluster_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
